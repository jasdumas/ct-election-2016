{
    "collab_server" : "",
    "contents" : "# Connecticut Presidential Election Results 2016\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(leaflet)\nlibrary(rvest)\nlibrary(dumas)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(rgdal)\nlibrary(tidyr)\n\nall_results <- read_csv(\"https://raw.githubusercontent.com/mkearney/presidential_election_county_results_2016/master/pres16results.csv\")\n\n# what is in here?\nhead(all_results)\n\n# what are fips? (https://www.census.gov/2010census/partners/pdf/FIPS_StateCounty_Code.pdf)\n# https://en.wikipedia.org/wiki/FIPS_140-2\nlevels(factor(all_results$fips))\n\n# Connecticut FIPS start with 09 - so lets grab those out are explore\nct_results <- all_results[grep(\"^09\", all_results$fips), ]\n\n# add the county names (8 in CT)\nct_results$county <- NA\n# these are the full fips numbers associated with each county\nfairfield <- \"09001\" \nhartford <- \"09003\"\nlitchfield <- \"09005\"\nmiddlesex <- \"09007\"\nnewhaven <- \"09009\"\nnewlondon <- \"09011\"\ntolland <- \"09013\"\nwindham <- \"09015\"\n\nct_results$county[which(ct_results$fips %in% fairfield)] <- \"Fairfield\"\nct_results$county[which(ct_results$fips %in% hartford)] <- \"Hartford\"\nct_results$county[which(ct_results$fips %in% litchfield)] <- \"Litchfield\"\nct_results$county[which(ct_results$fips %in% middlesex)] <- \"Middlesex\"\nct_results$county[which(ct_results$fips %in% newhaven)] <- \"New Haven\"\nct_results$county[which(ct_results$fips %in% newlondon)] <- \"New London\"\nct_results$county[which(ct_results$fips %in% tolland)] <- \"Tolland\"\nct_results$county[which(ct_results$fips %in% windham)] <- \"Windham\"\n\nView(ct_results)\n\n# exploratory data analysis\nggplot(ct_results, aes(x = cand_name, y = votes, fill = county)) +\n  geom_bar(stat = \"identity\")\n\n# CT level county shapefiles for 2015\ntmp2 = tempdir()\n#url2 = \"http://www2.census.gov/geo/tiger/GENZ2015/shp/cb_2015_09_county_within_ua_500k.zip\"\nurl2 = \"http://www2.census.gov/geo/tiger/GENZ2015/shp/cb_2015_us_county_500k.zip\"\nfile <- basename(url2)\ndownload.file(url2, file)\nunzip(file, exdir = tmp2)\nct_shp <- readOGR(dsn = tmp2, layer = \"cb_2015_09_county_within_ua_500k\", encoding = \"UTF-8\")\ndim(ct_shp)\nclass(ct_shp) # the human data is located at ct_shp@data\nView(ct_shp)\n\n# fix the FIPS number in the shape file for merging\nct_shp@data$fips <- paste0(ct_shp@data$STATEFP10, ct_shp@data$COUNTYFP10)\n\n# create a empty df\nct_econ <- data.frame(matrix(ncol=10, nrow = 0))\n\n# add some economic data from https://datausa.io/ for each county by web-scrapping\ncounty_urls <- c(\"https://datausa.io/profile/geo/fairfield-county-ct/\", \n                 \"https://datausa.io/profile/geo/hartford-county-ct/\", \n                 \"https://datausa.io/profile/geo/litchfield-county-ct/\", \n                 \"https://datausa.io/profile/geo/middlesex-county-ct/\", \n                 \"https://datausa.io/profile/geo/new-haven-county-ct/\", \n                 \"https://datausa.io/profile/geo/new-london-county-ct/\", \n                 \"https://datausa.io/profile/geo/tolland-county-ct/\", \n                 \"https://datausa.io/profile/geo/windham-county-ct/\")\n#  for loop for each of the counties\nfor (i in county_urls){\n  table <- read_html(i) %>% \n    html_nodes(\".stat-text+ .stat-value .stat-span\") %>% \n    html_text() %>% \n    data.frame()\n  # transpose into rows!\n  table_keep <- t(data.frame(table[c(1:9, 17), ]))\n  # append to a master data frame\n  ct_econ <- rbind(ct_econ, table_keep)\n}\n\n# add column names / mentally choose which values to keep after looking on the website\ncolnames(ct_econ) <- c(\"med_house_income14\", \n                       \"avg_male_income\", \n                       \"avg_female_income\", \n                       \"highest_income_race\", \n                       \"wage_gini\", \n                       \"largest_demo_poverty\", \n                       \"largest_race_poverty\", \n                       \"med_native_age\", \n                       \"med_foreign_age\", \n                       \"common_major\") \nct_econ$county <- c(\"Fairfield\", \"Hartford\", \"Litchfield\", \"Middlesex\", \n                    \"New Haven\", \"New London\", \"Tolland\", \"Windham\")\n\n# merge this with the ct_results with the economic data\nct_join <-  dplyr::full_join(ct_results, ct_econ)\n\n## let's try a specific candidate\nHRC <- ct_join[ct_join$cand_name == \"Hillary Clinton\", ]\n\n# merge this with the entire shapefile object\nct_shp2 <- sp::merge(x = ct_shp, y = HRC, by = \"fips\", all.x = F,\n                     duplicateGeoms=F)\n\n## ------------------------------ ##\n## let's get mapping with leaflet ##\n\n\npal <- colorBin(palette = \"BuPu\", domain = ct_shp2$votes, bins = 8)\n\n# pop values\nstate_popup <- paste0(\"<strong>County: </strong>\", \n                      ct_shp2$county, \n                      \"<br><strong>Median Household Income: </strong>\", \n                      ct_shp2$med_house_income14, \n                      \"<br><strong>Average Female Income: </strong>\",\n                      ct_shp2$avg_female_income)\n# plot the map\nleaflet(data = ct_shp2) %>%\n  addProviderTiles(\"CartoDB.Positron\") %>%\n  addPolygons(fillColor = ~pal(votes), \n              fillOpacity = 0.7, \n              color = \"#BDBDC3\", \n              weight = 1, \n              popup = state_popup) %>%\n  addLegend(\"bottomleft\", \n            pal = pal, \n            values = ~votes,\n            title = \"Total Votes\",\n            opacity = 1)\n\n\n\n\n\n\n\n\n\n",
    "created" : 1478880217004.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1317825018",
    "id" : "57EF46AD",
    "lastKnownWriteTime" : 1478963335,
    "last_content_update" : 1478963335646,
    "path" : "~/Desktop/R-directory/ct-election-2016/ct-election-2016-analysis.R",
    "project_path" : "ct-election-2016-analysis.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}