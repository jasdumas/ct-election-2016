{
    "collab_server" : "",
    "contents" : "---\nlayout: post\ntitle: \"Mapping & Web-scraping the 2016 Presidential Election Results in Connecticut\"\nsubtitle: \"Understanding my Neighbors with R and Leaflet\"\ntags: [rstats, r, election-2016, data-analysis]\nmaps: true\noutput: \n  html_document: \n    self_contained: no\n---\n  \n\n```{r setup, include=FALSE}\n# to be rendered as html for blog\nknitr::opts_chunk$set(\n\tfig.path = \"{{ site.url }}/post_data/election-results-ct-\",\n\tmessage = FALSE,\n\twarning = FALSE\n)\n```\n\nI, like many others across the country have been in total shock and mental disarray at the results from the election this past Tuesday. I'm not sure what to make of my fellow Americans voting for an outright racist, sexist, homophobic and xenophobic egomaniac and what that will mean for the United States and frankly the World. \n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">How do you model a variable for &quot;embarrassed when polled, but on Election Day votes true racist beliefs&quot;? <a href=\"https://t.co/f3aUhYHQTF\">https://t.co/f3aUhYHQTF</a></p>&mdash; Jasmine Dumas (@jasdumas) <a href=\"https://twitter.com/jasdumas/status/796349900644642816\">November 9, 2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n*This was in response to David Smith's original [tweet](https://twitter.com/revodavid/status/796340848896147460) about election forecasting* \n\nFrom the initial announcement of Donald Trump gaining the *magic* 270 electoral votes, I have been curious about the election data and eager to explore how my home state fared at the county level. I found a great visualization blog post from fellow useR, [Julia Silge](http://juliasilge.com/blog/Election-Mapping/) of her home state Utah which gave me ideas and starter code and county-level election data from [Mike Kearny](https://github.com/mkearney/presidential_election_county_results_2016)!\n\nHere is the analysis and approaches that I took:\n```{r}\nlibrary(readr)\nlibrary(dplyr)\nlibrary(leaflet)\nlibrary(rvest)\nlibrary(ggplot2)\nlibrary(rgdal)\nlibrary(tidyr)\nall_results <- read_csv(\"https://raw.githubusercontent.com/mkearney/presidential_election_county_results_2016/master/pres16results.csv\")\n\n# what is in here?\nhead(all_results)\n```\nI ended up not doing as much exploratory data analysis as intended. The data set is coded with FIPS numbers. [FIPS](https://www.census.gov/2010census/partners/pdf/FIPS_StateCounty_Code.pdf) state codes are numeric codes defined in U.S. Federal Information Processing Standard Publication to identify U.S. states. Connecticut FIPS codes start with 09 - so I grabbed those out from the entire data set to explore.\n```{r}\nhead(levels(factor(all_results$fips)))\nct_results <- all_results[grep(\"^09\", all_results$fips), ]\nhead(ct_results)\n```\nTo make things more readable, I added the county names to the data.frame and since Connecticut only has 8 counties, I can complete this step in an iterative approach by matching up the fips numbers.\n```{r}\n# add the county names (8 in CT)\nct_results$county <- NA\n# these are the full fips numbers associated with each county\nfairfield <- \"09001\" \nhartford <- \"09003\"\nlitchfield <- \"09005\"\nmiddlesex <- \"09007\"\nnewhaven <- \"09009\"\nnewlondon <- \"09011\"\ntolland <- \"09013\"\nwindham <- \"09015\"\n\nct_results$county[which(ct_results$fips %in% fairfield)] <- \"Fairfield\"\nct_results$county[which(ct_results$fips %in% hartford)] <- \"Hartford\"\nct_results$county[which(ct_results$fips %in% litchfield)] <- \"Litchfield\"\nct_results$county[which(ct_results$fips %in% middlesex)] <- \"Middlesex\"\nct_results$county[which(ct_results$fips %in% newhaven)] <- \"New Haven\"\nct_results$county[which(ct_results$fips %in% newlondon)] <- \"New London\"\nct_results$county[which(ct_results$fips %in% tolland)] <- \"Tolland\"\nct_results$county[which(ct_results$fips %in% windham)] <- \"Windham\"\n```\n\nHere is a bar chart using `ggplot2` of the election results by candidate, votes and county. I may add to this section later!\n```{r}\nggplot(ct_results, aes(x = cand_name, y = votes, fill = county)) +\n  geom_bar(stat = \"identity\")\n```\n\nShape files by county were downloaded with `rgdal`.\n```{r}\n# CT level county shapefiles for 2015\ntmp2 = tempdir()\nurl2 = \"http://www2.census.gov/geo/tiger/GENZ2015/shp/cb_2015_us_county_500k.zip\"\nfile <- basename(url2)\ndownload.file(url2, file)\nunzip(file, exdir = tmp2)\nct_shp <- readOGR(dsn = tmp2,\n                  layer = \"cb_2015_us_county_500k\", encoding = \"UTF-8\")\ndim(ct_shp)\n# fix the FIPS number in the shape file for merging\nct_shp@data$fips <- paste0(ct_shp@data$GEOID)\n```\n\nThis election was fueled by discontent and ignorance of the \"silent majority\" around social and economic policies, so I thought it was worthwhile to gather some socio-economic data from https://datausa.io/ to enhance the election data. *Data USA* is a data viz tool that uses open public data from https://www.data.gov/ to share insights on occupations, industries and education. This data was web-scraped using `rvest` as the aggregated statistics by county are nestled in a web page.\n```{r}\n# create a empty df\nct_econ <- data.frame(matrix(ncol=10, nrow = 0))\n\n# add some economic data from https://datausa.io/ for each county by web-scrapping\ncounty_urls <- c(\"https://datausa.io/profile/geo/fairfield-county-ct/\", \n                 \"https://datausa.io/profile/geo/hartford-county-ct/\", \n                 \"https://datausa.io/profile/geo/litchfield-county-ct/\", \n                 \"https://datausa.io/profile/geo/middlesex-county-ct/\", \n                 \"https://datausa.io/profile/geo/new-haven-county-ct/\", \n                 \"https://datausa.io/profile/geo/new-london-county-ct/\", \n                 \"https://datausa.io/profile/geo/tolland-county-ct/\", \n                 \"https://datausa.io/profile/geo/windham-county-ct/\")\n#  for loop for each of the counties\nfor (i in county_urls){\n  table <- read_html(i) %>% \n    html_nodes(\".stat-text+ .stat-value .stat-span\") %>% \n    html_text() %>% \n    data.frame()\n  # transpose into rows!\n  table_keep <- t(data.frame(table[c(1:9, 17), ]))\n  # append to a master data frame\n  ct_econ <- rbind(ct_econ, table_keep)\n}\n# add column names / mentally choose which values to keep after looking on the website\ncolnames(ct_econ) <- c(\"med_house_income14\", \n                       \"avg_male_income\", \n                       \"avg_female_income\", \n                       \"highest_income_race\", \n                       \"wage_gini\", \n                       \"largest_demo_poverty\", \n                       \"largest_race_poverty\", \n                       \"med_native_age\", \n                       \"med_foreign_age\", \n                       \"common_major\") \nct_econ$county <- c(\"Fairfield\", \"Hartford\", \"Litchfield\", \"Middlesex\", \n                    \"New Haven\", \"New London\", \"Tolland\", \"Windham\")\n```\n\nAt this point, I merged the election data with the socio-economic data after picking which stats I wanted to capture.\n```{r}\n# merge this with the ct_results with the economic data\nct_join <-  dplyr::full_join(ct_results, ct_econ)\n\n# full join the data set \nct_join <- dplyr::full_join(ct_shp@data, ct_join)\n\n# remove rows with NA's - i.e. remove everything except the choosen state\nct_clean = na.omit(ct_join)\n\n# merge this with the entire shapefile object\nct_shp2 <- ct_shp\nct_shp2 <- sp::merge(x = ct_shp2, y = ct_clean, \n                     by = \"fips\", all.x = F, \n                     duplicateGeoms=TRUE)\n# this is you're shapefile check\nplot(ct_shp2)\n```\n\nSpatial Analysis and mapping are a great way to visualize and understand this type of data, so I used `leaflet` for its interactivity to compare candidates and how many votes they received. This is the ground work for defining the color, popup info, and creating partitions for each candidate as their own base group on the map.\n```{r}\n# create seperate color patterns for each candidate for layers\nHRC <- ct_results[which(ct_results$cand_name == \"Hillary Clinton\"),] \nDT <- ct_results[which(ct_results$cand_name == \"Donald Trump\"),]\nGJ <- ct_results[which(ct_results$cand_name == \"Gary Johnson\"),]\nJT <- ct_results[which(ct_results$cand_name == \"Jill Stein\"),]\n\npal1 <- colorBin(palette = \"Blues\", domain = HRC$votes, bins = 8)\npal2 <- colorBin(palette = \"Reds\", domain = DT$votes, bins = 8)\npal3 <- colorBin(palette = \"YlOrRd\", domain = GJ$votes, bins = 8)\npal4 <- colorBin(palette = \"Greens\", domain = JT$votes, bins = 8)\n\n# pop values statewide regardless of candidate\nstate_popup <- paste0(\"<strong>County: </strong>\", \n                      ct_shp2$county, \n                      \"<br><strong>Total Amount of 2016 Voters: </strong>\", \n                      ct_shp2$total,\n                      \"<br><strong>Median Household Income: </strong>\", \n                      ct_shp2$med_house_income14, \n                      \"<br><strong>Average Female Income: </strong>\",\n                      ct_shp2$avg_female_income, \n                      \"<br><strong>Wage Equality Index: </strong>\", \n                      ct_shp2$wage_gini, \n                      \"<br><strong>Largest Demographic in Poverty: </strong>\", \n                      ct_shp2$largest_demo_poverty)\n```\n\nHere is our map widgets! Feel free to explore and adapt this code for your analysis of a given state!\n```{r}\n# plot the map(s)\nhrc_map <- leaflet(data = ct_shp2) %>%\n  addProviderTiles(\"CartoDB.Positron\") %>%\n  addPolygons(fillColor = ~pal1(HRC$votes), \n              fillOpacity = 0.7, \n              color = \"#BDBDC3\", \n              weight = 1, \n              popup = state_popup) %>%\n  addLegend(\"bottomright\", \n            pal = pal1, \n            values = ~HRC$votes,\n            title = \"Total Votes for Hillary Clinton: \",\n            opacity = 1)\nprint(hrc_map)\n\ndt_map <- leaflet(data = ct_shp2) %>%\n  addProviderTiles(\"CartoDB.Positron\") %>%\n  addPolygons(fillColor = ~pal2(DT$votes), \n              fillOpacity = 0.7, \n              color = \"#BDBDC3\", \n              weight = 1, \n              popup = state_popup) %>%\n  addLegend(\"bottomright\", \n            pal = pal2, \n            values = ~DT$votes,\n            title = \"Total Votes for Donald Trump: \",\n            opacity = 1) \nprint(dt_map)\n\n\ngj_map <- leaflet(data = ct_shp2) %>%\n  addProviderTiles(\"CartoDB.Positron\") %>%\n  addPolygons(fillColor = ~pal3(GJ$votes), \n              fillOpacity = 0.7, \n              color = \"#BDBDC3\", \n              weight = 1, \n              popup = state_popup) %>%\n  addLegend(\"bottomleft\", \n            pal = pal3, \n            values = ~GJ$votes,\n            title = \"Total Votes for Gary Johnson: \",\n            opacity = 1) \nprint(gj_map)\n\n\njt_map <- leaflet(data = ct_shp2) %>%\n  addProviderTiles(\"CartoDB.Positron\") %>%\n  addPolygons(fillColor = ~pal4(JT$votes), \n              fillOpacity = 0.7, \n              color = \"#BDBDC3\", \n              weight = 1, \n              popup = state_popup) %>%\n  addLegend(\"bottomleft\", \n            pal = pal4, \n            values = ~JT$votes,\n            title = \"Total Votes for Jill Stein: \",\n            opacity = 1) \nprint(jt_map)\n```\n\nHere is the repo for this work: https://github.com/jasdumas/ct-election-2016\n",
    "created" : 1478986364290.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "97183115",
    "id" : "19C19B6A",
    "lastKnownWriteTime" : 1478993403,
    "last_content_update" : 1478993403011,
    "path" : "~/Desktop/GitHub Clone Repos/jasdumas.github.io/_drafts/election-results-ct.Rmd",
    "project_path" : null,
    "properties" : {
        "last_setup_crc32" : "9CEA595D730486ab"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}